{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yPHJvFfEbYch"
      },
      "outputs": [],
      "source": [
        "import pandas as pd #used for data manipulation and analysis\n",
        "from sklearn.model_selection import train_test_split #split dataset for training and testing\n",
        "import math #python library for all mathematical functions\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score\n",
        "import random #generate random numbers or selections\n",
        "from sklearn.manifold import TSNE #TSNE class tool to visualize high-dimensional data\n",
        "#t-sne is a dimensionality reduction technique used in data visualization and analysis\n",
        "import seaborn as sns #for creating statistical graphics\n",
        "import plotly.express as px\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm #used to create progress bars\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from  torch.utils.data import Dataset, DataLoader #for handling and loading data when working with PyTorch\n",
        "import cv2 #pip install opencv-python #image processing library\n",
        "import urllib #provides functions for working with URLs and web requests\n",
        "from colabcode import ColabCode"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SlkZVrTZySGE"
      },
      "source": [
        "# Variational Autoencode Implementation (VAE)\n",
        "\n",
        "- A type of neural network architecture used for generative modeling and dimensionality reduction\n",
        "- A type of artificial neural network and data compression\n",
        "\n",
        "\n",
        "1. **Autoencoder**: Think of an autoencoder as a system that tries to compress information. It has two main parts:\n",
        "   - **Encoder**: This part takes input data (like images, text, or any kind of information) and converts it into a compressed representation, often called a \"latent space\" or \"encoding.\" This encoding is a condensed version of the input data.\n",
        "   - **Decoder**: The decoder takes this compressed representation and tries to recreate the original input data from it. It's like a reverse process of the encoder.\n",
        "\n",
        "2. **Variational**: The \"variational\" part of VAE means that it introduces a level of randomness into the encoding process. Instead of producing a single fixed encoding for a given input, VAE generates a probability distribution of possible encodings. This adds a level of uncertainty to the process.\n",
        "\n",
        "\n",
        "- **Encoding with Variability**: When you feed data into the VAE, it doesn't just produce one fixed encoding. Instead, it produces a range of possible encodings, represented as a probability distribution. This variability is useful because it allows the VAE to capture the inherent uncertainty in real-world data.\n",
        "\n",
        "- **Sampling**: From this probability distribution, a point is randomly sampled. This sampled point becomes the encoding for the input data. This random sampling is a key feature of VAE and is what makes it \"variational.\"\n",
        "\n",
        "- **Decoding**: The sampled encoding is then passed through the decoder to generate a reconstructed version of the original input data.\n",
        "\n",
        "- **Training**: During the training process, VAE tries to minimize the difference between the original data and the reconstructed data. It also tries to make the distribution of encodings as close to a standard Gaussian distribution as possible. This encourages the model to learn a meaningful and structured latent space representation of the data.\n",
        "\n",
        "So, in essence, a Variational Autoencoder is a neural network that can both compress data into a meaningful latent space and generate data from points in that latent space while introducing a level of randomness. This randomness makes it a powerful tool for various applications, including image generation, data denoising, and more, as it can capture the uncertainty and diversity present in real-world data.\n",
        "\n",
        "How it works:\n",
        "  encoder -> latent space -> decoder -> variational part\n",
        "\n",
        "**Encoder**\n",
        "  - takes the picture and tries to learn a compressed representation of it\n",
        "  - looks for essential features (e.g eyes, ears, snout, etc.)\n",
        "  - hidden code\n",
        "\n",
        "**Latent Space**\n",
        "  - special space where each point represents a unique feature decoder\n",
        "  - a place for hidden codes from the encoder\n",
        "\n",
        "**Decoder**\n",
        " - the decoder has learned how to tranform these latent codes into recognizable images\n",
        " - variational part\n",
        "    - in this part, it makes VAE special; it can generate slight difference from the original\n",
        "\n",
        "Directory Structure\n",
        "- input\n",
        "    - data\n",
        "- outputs\n",
        "- src\n",
        "    - model.py\n",
        "    - train.py\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "BGOBb3DWsBCN"
      },
      "outputs": [],
      "source": [
        "class VariationalAutoencoder(nn.Module):\n",
        "  #constructor to create a VAE object, allowing parameters num_feature and num_dim\n",
        "  def __init__(self, num_features = 8, num_dim = 784): #28x28 pixels\n",
        "    super(VariationalAutoencoder, self).__init__()\n",
        "    self.num_features = num_features\n",
        "    self.num_dim = num_dim\n",
        "\n",
        "    #creates a neural network layer that will be used for encoding input data\n",
        "    self.encoder_layer_1 = nn.Linear(in_features = self.num_dim, out_features = 512)\n",
        "\n",
        "    #creates another encoding layer that takes 512 features from the previous layer\n",
        "    #and produces num_features * 2\n",
        "    self.encoder_layer2 = nn.Linear(in_features = 512, out_features = (self.num_features*2))\n",
        "\n",
        "    #code responsible for reconstruction of data from the learned latent space\n",
        "    self.decoder_layer_1 = nn.Linear(in_features = self.num_features, out_features = 512)\n",
        "    self.decoder_layer_2 = nn.Linear(in_features = 512, out_features = (self.num_dim))\n",
        "\n",
        "\n",
        "  def reparameterize(self, mu, log_var):\n",
        "    '''\n",
        "    :param mu: mean from the encoder's latent space\n",
        "        - is like the desired average or center point inside the box\n",
        "    :param log_var: log variance from the encoder's latent space\n",
        "        - is like how spread out you want your random stuff to be inside the box(higher values mean more spread)\n",
        "    '''\n",
        "    std = torch.exp(0.5 * log_var) #standard deviation\n",
        "    eps = torch.randn_like(std) #randn_like as we need the same size\n",
        "    sample = mu + (eps * std) #sampling as if coming from the input space\n",
        "\n",
        "    return sample\n",
        "\n",
        "  def encode(self, x):\n",
        "    #encoding\n",
        "    x = F.relu(self.encoder_layer_1(x))\n",
        "    #relu (rectified linear unit) - a mathematical function commonly used in AI neural network\n",
        "    #ReLu(x) = max(0,x)\n",
        "    x = self.encoder_layer_2(x).view(-1, 2, self.num_features)\n",
        "\n",
        "    #get mu and log_var\n",
        "    mu = x[:, 0, :]\n",
        "    log_var = x[:, 1, :]\n",
        "\n",
        "    z = self.reparameterize(mu, log_var)\n",
        "\n",
        "    return z, mu, log_var\n",
        "  \n",
        "  def decode(self, z):\n",
        "      #decoding\n",
        "      x = F.relu.reparameterize(mu, log_var)\n",
        "      reconstruction, mu, log_var = self.encode(z, mu, log_var)\n",
        "\n",
        "      return reconstruction\n",
        "\n",
        "\n",
        "   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "UxL0i9RRyzCb"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[WinError 2] The system cannot find the file specified",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32me:\\Edward\\BCS\\Machine Learning\\Machine Learning 2\\20230918_ML2_Lab_Generative_AI_DoggoGenerator.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/Edward/BCS/Machine%20Learning/Machine%20Learning%202/20230918_ML2_Lab_Generative_AI_DoggoGenerator.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m ColabCode(port\u001b[39m=\u001b[39;49m\u001b[39m10000\u001b[39;49m)\n",
            "File \u001b[1;32md:\\Python\\Lib\\site-packages\\colabcode\\code.py:42\u001b[0m, in \u001b[0;36mColabCode.__init__\u001b[1;34m(self, port, password, authtoken, mount_drive, code, lab)\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_lab()\n\u001b[0;32m     41\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_code:\n\u001b[1;32m---> 42\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_install_code()\n\u001b[0;32m     43\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_install_extensions()\n\u001b[0;32m     44\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_server()\n",
            "File \u001b[1;32md:\\Python\\Lib\\site-packages\\colabcode\\code.py:49\u001b[0m, in \u001b[0;36mColabCode._install_code\u001b[1;34m()\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m     48\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_install_code\u001b[39m():\n\u001b[1;32m---> 49\u001b[0m     subprocess\u001b[39m.\u001b[39;49mrun([\u001b[39m\"\u001b[39;49m\u001b[39mwget\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mhttps://code-server.dev/install.sh\u001b[39;49m\u001b[39m\"\u001b[39;49m], stdout\u001b[39m=\u001b[39;49msubprocess\u001b[39m.\u001b[39;49mPIPE)\n\u001b[0;32m     50\u001b[0m     subprocess\u001b[39m.\u001b[39mrun(\n\u001b[0;32m     51\u001b[0m         [\u001b[39m\"\u001b[39m\u001b[39msh\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39minstall.sh\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m--version\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mCODESERVER_VERSION\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m],\n\u001b[0;32m     52\u001b[0m         stdout\u001b[39m=\u001b[39msubprocess\u001b[39m.\u001b[39mPIPE,\n\u001b[0;32m     53\u001b[0m     )\n",
            "File \u001b[1;32md:\\Python\\Lib\\subprocess.py:548\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    545\u001b[0m     kwargs[\u001b[39m'\u001b[39m\u001b[39mstdout\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m PIPE\n\u001b[0;32m    546\u001b[0m     kwargs[\u001b[39m'\u001b[39m\u001b[39mstderr\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m PIPE\n\u001b[1;32m--> 548\u001b[0m \u001b[39mwith\u001b[39;00m Popen(\u001b[39m*\u001b[39;49mpopenargs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs) \u001b[39mas\u001b[39;00m process:\n\u001b[0;32m    549\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    550\u001b[0m         stdout, stderr \u001b[39m=\u001b[39m process\u001b[39m.\u001b[39mcommunicate(\u001b[39minput\u001b[39m, timeout\u001b[39m=\u001b[39mtimeout)\n",
            "File \u001b[1;32md:\\Python\\Lib\\subprocess.py:1026\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize, process_group)\u001b[0m\n\u001b[0;32m   1022\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtext_mode:\n\u001b[0;32m   1023\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39mTextIOWrapper(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr,\n\u001b[0;32m   1024\u001b[0m                     encoding\u001b[39m=\u001b[39mencoding, errors\u001b[39m=\u001b[39merrors)\n\u001b[1;32m-> 1026\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_execute_child(args, executable, preexec_fn, close_fds,\n\u001b[0;32m   1027\u001b[0m                         pass_fds, cwd, env,\n\u001b[0;32m   1028\u001b[0m                         startupinfo, creationflags, shell,\n\u001b[0;32m   1029\u001b[0m                         p2cread, p2cwrite,\n\u001b[0;32m   1030\u001b[0m                         c2pread, c2pwrite,\n\u001b[0;32m   1031\u001b[0m                         errread, errwrite,\n\u001b[0;32m   1032\u001b[0m                         restore_signals,\n\u001b[0;32m   1033\u001b[0m                         gid, gids, uid, umask,\n\u001b[0;32m   1034\u001b[0m                         start_new_session, process_group)\n\u001b[0;32m   1035\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m   1036\u001b[0m     \u001b[39m# Cleanup if the child failed starting.\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m     \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m \u001b[39mfilter\u001b[39m(\u001b[39mNone\u001b[39;00m, (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstdin, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstdout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr)):\n",
            "File \u001b[1;32md:\\Python\\Lib\\subprocess.py:1538\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_gid, unused_gids, unused_uid, unused_umask, unused_start_new_session, unused_process_group)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[39m# Start the process\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1538\u001b[0m     hp, ht, pid, tid \u001b[39m=\u001b[39m _winapi\u001b[39m.\u001b[39;49mCreateProcess(executable, args,\n\u001b[0;32m   1539\u001b[0m                              \u001b[39m# no special security\u001b[39;49;00m\n\u001b[0;32m   1540\u001b[0m                              \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m   1541\u001b[0m                              \u001b[39mint\u001b[39;49m(\u001b[39mnot\u001b[39;49;00m close_fds),\n\u001b[0;32m   1542\u001b[0m                              creationflags,\n\u001b[0;32m   1543\u001b[0m                              env,\n\u001b[0;32m   1544\u001b[0m                              cwd,\n\u001b[0;32m   1545\u001b[0m                              startupinfo)\n\u001b[0;32m   1546\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m   1547\u001b[0m     \u001b[39m# Child is launched. Close the parent's copy of those pipe\u001b[39;00m\n\u001b[0;32m   1548\u001b[0m     \u001b[39m# handles that only the child should have open.  You need\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[39m# pipe will not close when the child process exits and the\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m     \u001b[39m# ReadFile will hang.\u001b[39;00m\n\u001b[0;32m   1553\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_close_pipe_fds(p2cread, p2cwrite,\n\u001b[0;32m   1554\u001b[0m                          c2pread, c2pwrite,\n\u001b[0;32m   1555\u001b[0m                          errread, errwrite)\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified"
          ]
        }
      ],
      "source": [
        "ColabCode(port=10000)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
